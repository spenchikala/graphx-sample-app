

---------------------------------------------------------------------------------------------------------
//
// Reference:
// http://spark.apache.org/docs/latest/graphx-programming-guide.html
//
---------------------------------------------------------------------------------------------------------
//
//  Launch Spark Scala Shell:
//

c:
set JAVA_HOME=c:\dev\java\jdk1.6.0_45
set PATH=%PATH%;%JAVA_HOME%\bin

set SCALA_HOME=C:\dev\languages\scala
set PATH=%PATH%;%SCALA_HOME%\bin

set SPARK_HOME=c:\dev\servers\spark-1.0.1-bin-hadoop2
set PATH=%PATH%;%SPARK_HOME%\bin

cd c:\dev\projects\BigDataBootCampLabs\SparkWorkshop\SparkWorkshopLabs\graphx-sample-app

spark-shell.cmd

sc


// Spark UI:
http://localhost:4040
---------------------------------------------------------------------------------------------------------
c:
set JAVA_HOME=c:\dev\java\jdk1.6.0_45
set PATH=%PATH%;%JAVA_HOME%\bin

cd %JAVA_HOME%\bin

jps

------------------------------------------------------------------------------------------------------
//
// Graph Algorithms:
//

// PageRank Example:

//
// Reference:
// http://spark.apache.org/docs/latest/graphx-programming-guide.html#pagerank
//

//
// Use Case Description:

PageRank measures the importance of each vertex in a graph, assuming an edge from u to v represents an endorsement of v’s importance by u. For example, if a Twitter user is followed by many others, the user will be ranked highly.

GraphX comes with static and dynamic implementations of PageRank as methods on the PageRank object. Static PageRank runs for a fixed number of iterations, while dynamic PageRank runs until the ranks converge (i.e., stop changing by more than a specified tolerance). GraphOps allows calling these algorithms directly as methods on Graph.

GraphX also includes an example social network dataset that we can run PageRank on. A set of users is given in graphx/data/users.txt, and a set of relationships between users is given in graphx/data/followers.txt. We compute the PageRank of each user as follows:
//

// Import the Scala RDD classes.
import org.apache.spark._
import org.apache.spark.graphx._
import org.apache.spark.rdd.RDD

// Load the user data (Nodes).

val users = sc.textFile("graphx/data/users.txt").map {
	line => val fields = line.split(",")
	(fields(0).toLong, fields(1))
}

// Get number of entries in users RDD.
users.count()

// Print the users
println(users.collect().mkString("\n"))


// Load the Followers data (Edges/Relationship)
val graph = GraphLoader.edgeListFile(sc, "graphx/data/followers.txt")

// Run PageRank
val ranks = graph.pageRank(0.0001).vertices

ranks.count()

ranks.take(5)

// Print the Ranks result
println(ranks.collect().mkString("\n"))


// Join the ranks with the usernames
val ranksByUsername = users.join(ranks).map {
	case (id, (username, rank)) => (username, rank)
}

// Print the ranksByUsername result
println(ranksByUsername.collect().mkString("\n"))

---------------------------------------------------------------------------------------------------------

// Page Rank - Take 2.

// Import the Scala RDD classes.
import org.apache.spark._
import org.apache.spark.graphx._
import org.apache.spark.rdd.RDD

// Load my user data and parse into tuples of user id and attribute list
val users = (sc.textFile("graphx/data/users.txt")
	.map(line => line.split(",")).map( parts => (parts.head.toLong, parts.tail) ))

// Parse the edge data which is already in userId -> userId format
val followerGraph = GraphLoader.edgeListFile(sc, "graphx/data/followers.txt")

// Attach the user attributes
val graph = followerGraph.outerJoinVertices(users) {
	case (uid, deg, Some(attrList)) => attrList
	// Some users may not have attributes so we set them as empty
	case (uid, deg, None) => Array.empty[String]
}

// Restrict the graph to users with usernames and names
val subgraph = graph.subgraph(vpred = (vid, attr) => attr.size == 2)

// Compute the PageRank
val pagerankGraph = subgraph.pageRank(0.001)

// Get the attributes of the top pagerank users
val userInfoWithPageRank = subgraph.outerJoinVertices(pagerankGraph.vertices) {
	case (uid, attrList, Some(pr)) => (pr, attrList.toList)
	case (uid, attrList, None) => (0.0, attrList.toList)
}

println(userInfoWithPageRank.vertices.top(5)(Ordering.by(_._2._1)).mkString("\n"))

---------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------
// Connected Components Example:

//
// Reference:
// http://spark.apache.org/docs/latest/graphx-programming-guide.html#connected-components
//

//
// Use Case Description:
Connected components algorithm labels each connected component of the graph with the ID of its lowest-numbered vertex. For example, in a social network, connected components can approximate clusters. GraphX contains an implementation of the algorithm in the ConnectedComponents object, and we compute the connected components of the example social network dataset from the PageRank section as follows:
//


// Load user data
val users = sc.textFile("graphx/data/users.txt").map { line =>
	val fields = line.split(",")
	(fields(0).toLong, fields(1))
}

// Load the graph as in the PageRank example
val graph = GraphLoader.edgeListFile(sc, "graphx/data/followers.txt")

// Find the connected components
val cc = graph.connectedComponents().vertices

// Join the connected components with the usernames
val ccByUsername = users.join(cc).map {
	case (id, (username, cc)) => (username, cc)
}

// Print the result
println(ccByUsername.collect().mkString("\n"))

---------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------
//
// Triangle Counting Example
//

//
// Reference:
// http://spark.apache.org/docs/latest/graphx-programming-guide.html#connected-components
//

//
// Use Case Description:
//
// A vertex is part of a triangle when it has two adjacent vertices with an edge between them. 
// GraphX implements a triangle counting algorithm in the TriangleCount object that determines 
// the number of triangles passing through each vertex, providing a measure of clustering. 
// We compute the triangle count of the social network dataset from the PageRank section. 
// Note that TriangleCount requires the edges to be in canonical orientation (srcId < dstId) 
// and the graph to be partitioned using Graph.partitionBy. 
// Also note that Graph.partitionBy is broken in Spark 1.0.0 due to SPARK-1931; 
// see the suggested workarounds above.


import org.apache.spark._
import org.apache.spark.graphx._
import org.apache.spark.rdd.RDD

// Define our own version of partitionBy to work around SPARK-1931
import org.apache.spark.HashPartitioner
def partitionBy[ED](edges: RDD[Edge[ED]], partitionStrategy: PartitionStrategy): RDD[Edge[ED]] = {
	val numPartitions = edges.partitions.size
	edges.map(e => (partitionStrategy.getPartition(e.srcId, e.dstId, numPartitions), e))
		.partitionBy(new HashPartitioner(numPartitions))
		.mapPartitions(_.map(_._2), preservesPartitioning = true)
}

// Join the triangle counts with the usernames
val users = sc.textFile("graphx/data/users.txt").map { line =>
	val fields = line.split(",")
	(fields(0).toLong, fields(1))
}

// Load the edges in canonical order and partition the graph for triangle count
val unpartitionedGraph = GraphLoader.edgeListFile(sc, "graphx/data/followers.txt", true)

// 
// Broken
//
// val graph = Graph(partitionBy(unpartitionedGraph.edges, PartitionStrategy.RandomVertexCut), unpartitionedGraph.vertices)
//


val graph = Graph(unpartitionedGraph.vertices, partitionBy(unpartitionedGraph.edges, PartitionStrategy.RandomVertexCut))


// Find the triangle count for each vertex
val triCounts = graph.triangleCount().vertices

val triCountByUsername = users.join(triCounts).map { case (id, (username, tc)) =>
	(username, tc)
}

// Print the result
println(triCountByUsername.collect().mkString("\n"))
---------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------

//
// Graph Data Pipeline:
//

//
// Use Case:
Build a graph from some text files
Restrict the graph to important relationships and users
Run page-rank on the sub-graph
Finally return attributes associated with the top users.

//
// Solution:
//
We can do all of this in just a few lines with GraphX.



// Load my user data and parse into tuples of user id and attribute list
val users = (sc.textFile("graphx/data/users.txt")
	.map(line => line.split(",")).map( parts => (parts.head.toLong, parts.tail) ))

// Parse the edge data which is already in userId -> userId format
val followerGraph = GraphLoader.edgeListFile(sc, "graphx/data/followers.txt")

// Attach the user attributes
val graph = followerGraph.outerJoinVertices(users) {
	case (uid, deg, Some(attrList)) => attrList
	// Some users may not have attributes so we set them as empty
	case (uid, deg, None) => Array.empty[String]
}

// Restrict the graph to users with usernames and names
val subgraph = graph.subgraph(vpred = (vid, attr) => attr.size == 2)

// Compute the PageRank
val pagerankGraph = subgraph.pageRank(0.001)

// Get the attributes of the top pagerank users
val userInfoWithPageRank = subgraph.outerJoinVertices(pagerankGraph.vertices) {
	case (uid, attrList, Some(pr)) => (pr, attrList.toList)
	case (uid, attrList, None) => (0.0, attrList.toList)
}

println(userInfoWithPageRank.vertices.top(5)(Ordering.by(_._2._1)).mkString("\n"))


---------------------------------------------------------------------------------------------------------

